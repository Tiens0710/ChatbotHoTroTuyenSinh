{
  "_name_or_path": "vinai/phobert-base-v2",
  "architectures": [
    "RobertaForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.3,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 768,
  "id2label": {
    "0": "greeting",
    "1": "goodbye",
    "2": "creator",
    "3": "name",
    "4": "salutaion",
    "5": "task",
    "6": "introduced",
    "7": "address",
    "8": "hotline",
    "9": "nature",
    "10": "adMajor",
    "11": "adZone",
    "12": "adUni",
    "13": "adMaster",
    "14": "adProcess",
    "15": "adTime",
    "16": "decision",
    "17": "applyfee",
    "18": "tuition",
    "19": "schoolarship",
    "20": "dorm",
    "21": "quality",
    "22": "edu",
    "23": "eGra",
    "24": "AP",
    "25": "job",
    "26": "LikeIT",
    "27": "sbFacuLtyIT",
    "28": "sbISE",
    "29": "sbLSCM",
    "30": "sbIM",
    "31": "sbCM",
    "32": "sbCET",
    "33": "sbEET",
    "34": "SBEEET",
    "35": "sbMET",
    "36": "sbCAET",
    "37": "sbFT",
    "38": "sbBT",
    "39": "sbFB",
    "40": "sbAC",
    "41": "sbBAdministration",
    "42": "sbLaw",
    "43": "sbEL",
    "44": "introceCS",
    "45": "obCS",
    "46": "knowCS",
    "47": "jobCS",
    "48": "introceDS",
    "49": "obDS",
    "50": "knowDS",
    "51": "jobDS",
    "52": "introceLSCM",
    "53": "obLSCM",
    "54": "knowLSCM",
    "55": "jobLSCM",
    "56": "introceIT",
    "57": "obIT",
    "58": "knowIT",
    "59": "ctCNTT",
    "60": "introceSE",
    "61": "obSE",
    "62": "knowSE",
    "63": "cdKTPM",
    "64": "introceCAET",
    "65": "obCAET",
    "66": "knowCAET",
    "67": "introceMET",
    "68": "obMET",
    "69": "knowMET",
    "70": "introceBAdministration",
    "71": "obBAdministration",
    "72": "knowBAdministration",
    "73": "introceEL",
    "74": "obEL",
    "75": "knowEL",
    "76": "introceFB",
    "77": "obFB",
    "78": "knowFB",
    "79": "cdFB",
    "80": "introceLaw",
    "81": "ctLuat",
    "82": "thucTapLuat",
    "83": "knowLaw"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "AP": 24,
    "LikeIT": 26,
    "SBEEET": 34,
    "adMajor": 10,
    "adMaster": 13,
    "adProcess": 14,
    "adTime": 15,
    "adUni": 12,
    "adZone": 11,
    "address": 7,
    "applyfee": 17,
    "cdFB": 79,
    "cdKTPM": 63,
    "creator": 2,
    "ctCNTT": 59,
    "ctLuat": 81,
    "decision": 16,
    "dorm": 20,
    "eGra": 23,
    "edu": 22,
    "goodbye": 1,
    "greeting": 0,
    "hotline": 8,
    "introceBAdministration": 70,
    "introceCAET": 64,
    "introceCS": 44,
    "introceDS": 48,
    "introceEL": 73,
    "introceFB": 76,
    "introceIT": 56,
    "introceLSCM": 52,
    "introceLaw": 80,
    "introceMET": 67,
    "introceSE": 60,
    "introduced": 6,
    "job": 25,
    "jobCS": 47,
    "jobDS": 51,
    "jobLSCM": 55,
    "knowBAdministration": 72,
    "knowCAET": 66,
    "knowCS": 46,
    "knowDS": 50,
    "knowEL": 75,
    "knowFB": 78,
    "knowIT": 58,
    "knowLSCM": 54,
    "knowLaw": 83,
    "knowMET": 69,
    "knowSE": 62,
    "name": 3,
    "nature": 9,
    "obBAdministration": 71,
    "obCAET": 65,
    "obCS": 45,
    "obDS": 49,
    "obEL": 74,
    "obFB": 77,
    "obIT": 57,
    "obLSCM": 53,
    "obMET": 68,
    "obSE": 61,
    "quality": 21,
    "salutaion": 4,
    "sbAC": 40,
    "sbBAdministration": 41,
    "sbBT": 38,
    "sbCAET": 36,
    "sbCET": 32,
    "sbCM": 31,
    "sbEET": 33,
    "sbEL": 43,
    "sbFB": 39,
    "sbFT": 37,
    "sbFacuLtyIT": 27,
    "sbIM": 30,
    "sbISE": 28,
    "sbLSCM": 29,
    "sbLaw": 42,
    "sbMET": 35,
    "schoolarship": 19,
    "task": 5,
    "thucTapLuat": 82,
    "tuition": 18
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 258,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "problem_type": "single_label_classification",
  "tokenizer_class": "PhobertTokenizer",
  "torch_dtype": "float32",
  "transformers_version": "4.30.2",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 64001
}
